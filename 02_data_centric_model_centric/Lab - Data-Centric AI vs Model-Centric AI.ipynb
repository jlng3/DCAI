{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e5916b2",
   "metadata": {},
   "source": [
    "# Lab: Data-Centric vs Model-Centric approaches\n",
    "\n",
    "This lab gives an introduction to data-centric vs model-centric approaches to machine learning problems, showing how data-centric approaches can outperform purely model-centric approaches.\n",
    "\n",
    "In this lab, we'll build a classifier for product reviews (restricted to the magazine category), like:\n",
    "\n",
    "> Excellent! I look forward to every issue. I had no idea just how much I didn't know.  The letters from the subscribers are educational, too.\n",
    "\n",
    "Label: ⭐️⭐️⭐️⭐️⭐️ (good)\n",
    "\n",
    "> My son waited and waited, it took the 6 weeks to get delivered that they said it would but when it got here he was so dissapointed, it only took him a few minutes to read it.\n",
    "\n",
    "Label: ⭐️ (bad)\n",
    "\n",
    "We'll work with a dataset that has some issues, and we'll see how we can squeeze only so much performance out of the model by being clever about model choice, searching for better hyperparameters, etc. Then, we'll take a look at the data (as any good data scientist should), develop an understanding of the issues, and use simple approaches to improve the data. Finally, we'll see how improving the data can improve results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5874cd",
   "metadata": {},
   "source": [
    "## Installing software\n",
    "\n",
    "For this lab, you'll need to install [scikit-learn](https://scikit-learn.org/) and [pandas](https://pandas.pydata.org/). If you don't have them installed already, you can install them by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3e0ee93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\public\\anaconda3\\lib\\site-packages (0.24.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\public\\anaconda3\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\public\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\public\\anaconda3\\lib\\site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\public\\anaconda3\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\public\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\public\\anaconda3\\lib\\site-packages (from scikit-learn) (1.6.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\public\\anaconda3\\lib\\site-packages (from scikit-learn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\public\\anaconda3\\lib\\site-packages (from scikit-learn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dbfce6",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "\n",
    "First, let's load the train/test sets and take a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7405df2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a633542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>my mother kept every Christmas issue for years...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>I give this magazine to my niece for her birth...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>Love it!  Great Magazine!!</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>Order this and a subscription to Computer Shop...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Best DIY magazine for beginners!!</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review label\n",
       "35   my mother kept every Christmas issue for years...  good\n",
       "337  I give this magazine to my niece for her birth...  good\n",
       "485                         Love it!  Great Magazine!!  good\n",
       "520  Order this and a subscription to Computer Shop...   bad\n",
       "133                  Best DIY magazine for beginners!!  good"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('reviews_train.csv')\n",
    "test = pd.read_csv('reviews_test.csv')\n",
    "\n",
    "test.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6446a894",
   "metadata": {},
   "source": [
    "# Training a baseline model\n",
    "\n",
    "There are many approaches for training a sequence classification model for text data. In this lab, we're giving you code that mirrors what you find if you look up [how to train a text classifier](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html), where we'll train an SVM on [tf-idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) features (numeric representations of each text field based on word occurrences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26e13e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d47f9a8b-a69c-4896-91af-973030781824",
   "metadata": {},
   "source": [
    "sgd_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14a09cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sgd_clf.fit(train['review'], train['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8885717d",
   "metadata": {},
   "source": [
    "## Evaluating model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2850df30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60677a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(clf):\n",
    "    pred = clf.predict(test['review'])\n",
    "    acc = metrics.accuracy_score(test['label'], pred)\n",
    "    print(f'Accuracy: {100*acc:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f77729fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.2%\n"
     ]
    }
   ],
   "source": [
    "evaluate(sgd_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3880fa",
   "metadata": {},
   "source": [
    "## Trying another model\n",
    "\n",
    "76% accuracy is not great for this binary classification problem. Can you do better with a different model, or by tuning hyperparameters for the SVM trained with SGD?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bdf2c7",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Can you train a more accurate model on the dataset (without changing the dataset)? You might find this [scikit-learn classifier comparison](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html) handy, as well as the [documentation for supervised learning in scikit-learn](https://scikit-learn.org/stable/supervised_learning.html).\n",
    "\n",
    "One idea for a model you could try is a [naive Bayes classifier](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html).\n",
    "\n",
    "You could also try experimenting with different values of the model hyperparameters, perhaps tuning them via a [grid search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). \n",
    "\n",
    "Or you can even try training multiple different models and [ensembling their predictions](https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier), a strategy often used to win prediction competitions like Kaggle.\n",
    "\n",
    "**Advanced:** If you want to be more ambitious, you could try an even fancier model, like training a Transformer neural network. If you go with that, you'll want to fine-tune a pre-trained model. This [guide from HuggingFace](https://huggingface.co/docs/transformers/training) may be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ca681e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.3%\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# Naive Bayes (as suggested)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "nb_clf.fit(train['review'], train['label'])\n",
    "#evaluate your model and see if it does better\n",
    "# than the ones we provided\n",
    "evaluate(nb_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01eb3af6-79b8-43fe-8059-d20de4ab3440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "Accuracy: 77.1%\n"
     ]
    }
   ],
   "source": [
    "# Grid Search using Support Vector Machine\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', svm.SVC()),\n",
    "])\n",
    "\n",
    "# Define the parameter grid for search (note the double underscore)\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'clf__C': [1, 10, 100],\n",
    "    'clf__kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv = 10, n_jobs = -1, \n",
    "                          verbose = 1)\n",
    "grid_search.fit(train['review'], train['label'])\n",
    "\n",
    "\n",
    "# Evaluate accuracy\n",
    "evaluate(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2e955966-41fe-4124-aa80-c463b65bf3da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Ensemble Learning\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# For algorithms that can take non-numeric output\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', None),\n",
    "])\n",
    "\n",
    "# Define Classifiers\n",
    "dtc = DecisionTreeClassifier()\n",
    "rfc = RandomForestClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "adaboost = AdaBoostClassifier()\n",
    "bagging = BaggingClassifier()\n",
    "\n",
    "# Define Parameter Grids\n",
    "dtc_param_grid = {\n",
    "    'clf__criterion': ['gini', 'entropy'],\n",
    "    'clf__max_depth': [5, 10, 15, None],\n",
    "    'clf__min_samples_split': [2, 5, 10],\n",
    "    'clf__min_samples_leaf': [1, 2, 4],\n",
    "    'clf__max_features': ['auto', 'sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "rfc_param_grid = {\n",
    "    'clf__n_estimators': [50, 100, 200],\n",
    "    'clf__criterion': ['gini', 'entropy'],\n",
    "    'clf__max_depth': [5, 10, 15, None],\n",
    "    'clf__min_samples_split': [2, 5, 10],\n",
    "    'clf__min_samples_leaf': [1, 2, 4],\n",
    "    'clf__max_features': ['auto', 'sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "knn_param_grid = {\n",
    "    'clf__n_neighbors': [3, 5, 7],\n",
    "    'clf__weights': ['uniform', 'distance'],\n",
    "    'clf__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'clf__leaf_size': [10, 20, 30, 40, 50]\n",
    "}\n",
    "\n",
    "bagging_param_grid = {\n",
    "    'clf__n_estimators': [50, 100, 200],\n",
    "    'clf__max_samples': [0.5, 0.75, 1],\n",
    "    'clf__max_features': [0.5, 0.75, 1],\n",
    "    'clf__bootstrap': [True, False],\n",
    "    'clf__bootstrap_features': [True, False],\n",
    "    'clf__n_jobs':[-1]\n",
    "}\n",
    "\n",
    "# Group the classifiers and their parameters together for grid search\n",
    "classifiers = [\n",
    "    (dtc, dtc_param_grid),\n",
    "    (rfc, rfc_param_grid),\n",
    "    (knn, knn_param_grid),\n",
    "    (bagging, bagging_param_grid)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4f0d9f5f-322f-4407-adbd-08490a17e8f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 288 candidates, totalling 2880 fits\n",
      "Best parameters for DecisionTreeClassifier: {'clf__criterion': 'gini', 'clf__max_depth': None, 'clf__max_features': None, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2}\n",
      "Best cross-validation score for DecisionTreeClassifier: 0.7472306639473055\n",
      "Fitting 10 folds for each of 864 candidates, totalling 8640 fits\n",
      "Best parameters for RandomForestClassifier: {'clf__criterion': 'gini', 'clf__max_depth': None, 'clf__max_features': None, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 200}\n",
      "Best cross-validation score for RandomForestClassifier: 0.825681078379729\n",
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n",
      "Best parameters for KNeighborsClassifier: {'clf__algorithm': 'auto', 'clf__leaf_size': 10, 'clf__n_neighbors': 7, 'clf__weights': 'uniform'}\n",
      "Best cross-validation score for KNeighborsClassifier: 0.6501600551075815\n",
      "Fitting 10 folds for each of 108 candidates, totalling 1080 fits\n",
      "Best parameters for BaggingClassifier: {'clf__bootstrap': False, 'clf__bootstrap_features': False, 'clf__max_features': 0.75, 'clf__max_samples': 0.75, 'clf__n_estimators': 200, 'clf__n_jobs': -1}\n",
      "Best cross-validation score for BaggingClassifier: 0.804377991184588\n",
      "\n",
      "Best model: RandomForestClassifier with optimized parameters: {'clf__criterion': 'gini', 'clf__max_depth': None, 'clf__max_features': None, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# To identify the best model\n",
    "best_clf = None\n",
    "best_params = {}\n",
    "best_score = 0.0\n",
    "\n",
    "for clf, param_grid in classifiers:\n",
    "    pipeline.set_params(clf = clf)\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid = param_grid,\n",
    "        cv = 10,\n",
    "        n_jobs = -1,\n",
    "        scoring = 'accuracy',\n",
    "        verbose = 1\n",
    "    )\n",
    "        \n",
    "    grid_search.fit(train['review'], train['label'])\n",
    "    print(f\"Best parameters for {clf.__class__.__name__}: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation score for {clf.__class__.__name__}: {grid_search.best_score_}\")\n",
    "        \n",
    "    if grid_search.best_score_ > best_score:\n",
    "        best_clf = clf\n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = grid_search.best_score_\n",
    "\n",
    "# Print the best model after grid search\n",
    "print(f\"\\nBest model: {best_clf.__class__.__name__} with optimized parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ec9caf62-4745-4b1d-b4f7-040b772fe8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.1%\n"
     ]
    }
   ],
   "source": [
    "# Set the best model and its optimized parameters\n",
    "pipeline.set_params(clf = best_clf, **best_params)\n",
    "\n",
    "# Fit the best model on the whole training data\n",
    "pipeline.fit(train['review'], train['label'])\n",
    "\n",
    "# Evaluate the results\n",
    "evaluate(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb3cb9b-fe71-4652-abc7-18b286b671a1",
   "metadata": {},
   "source": [
    "<font color = red>**Important Note:** </font> <br>\n",
    "The `clf__` (double underscore) is crucial when defining the hyperparameter(s). In the process above, `scikit-learn`'s `Pipeline` object is used to chain the text preprocessing steps and the classifier model together. In the pipeline, each step is <font color = red>**identified by a name defined** </font>, which is passed as a parameter to the constructor of each step. For example, in the code:\n",
    "\n",
    "```\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', None),\n",
    "])\n",
    "```\n",
    "\n",
    "Three steps are defined in the pipeline, namely `vect`, `tfidf` and `clf`. When specifying the hyperparameters for the classifier model, it is important to refer to them using the <font color = red>**name of the step**</font> and the <font color = red>**name of the hyperparameter**</font>, separated by <font color = red>**two underscores (__)**</font>. This is called the <font color = red>**\"double underscore notation\"**</font> or <font color = red>**\"dot notation\"**</font>. \n",
    "\n",
    "So, for example, to specify the `max_depth` hyperparameter for the `DecisionTreeClassifier`, which is the classifier currently used in the pipeline, the hyperparameters are specified as '`clf__max_depth`', where '`clf`' is the name of the '`clf`' step in the pipeline and '`max_depth`' is the name of the hyperparameter you want to tune.\n",
    "\n",
    "The reason of using this notation is because, when calling `GridSearchCV` with the pipeline object and the hyperparameter grid, `scikit-learn` needs to know which step in the pipeline each hyperparameter belongs to. By using the double underscore notation, you are telling `scikit-learn` that the hyperparameter belongs to the '`clf`' step in the pipeline. <font color = red>**If you don't use this notation, `scikit-learn` doesn't know which step the hyperparameter belongs to and raises an error.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f5fe1831-e960-49c2-a835-8010dc5a6077",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function tokenize_function at 0x0000024A026183A0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6666 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/6666 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6666\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10\n",
      "  Number of trainable parameters = 66955010\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 09:48, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10, training_loss=0.6968923091888428, metrics={'train_runtime': 731.1075, 'train_samples_per_second': 0.109, 'train_steps_per_second': 0.014, 'total_flos': 10597391892480.0, 'train_loss': 0.6968923091888428, 'epoch': 0.01})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using transformer neural network\n",
    "import numpy as np\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import datasets\n",
    "from datasets import Dataset, DatasetDict, ClassLabel\n",
    "\n",
    "# Reformat the data to be suitable with Hugging Face Dataset class\n",
    "label_map = {\"bad\": 0, \"good\": 1}\n",
    "dataset_train = Dataset.from_dict({\"label\": train[\"label\"].map(label_map), \"text\": train[\"review\"].values})\n",
    "dataset_test = Dataset.from_dict({\"label\": test[\"label\"].map(label_map), \"text\": test[\"review\"].values})\n",
    "\n",
    "# Model configuration\n",
    "model_name = \"distilbert-base-uncased\"  # which pretrained neural network weights to load for fine-tuning on our data\n",
    "max_training_steps = 10  # how many iterations our network will be trained for\n",
    "model_folder = \"test_trainer\"  # file where model will be saved after training\n",
    "\n",
    "# Train the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "train_tokenized_dataset = dataset_train.map(tokenize_function, batched=True)\n",
    "train_tokenized_dataset = train_tokenized_dataset.cast_column(\"label\", ClassLabel(names = [\"0\", \"1\"]))\n",
    "\n",
    "test_tokenized_dataset = dataset_test.map(tokenize_function, batched=True)\n",
    "test_tokenized_dataset = test_tokenized_dataset.cast_column(\"label\", ClassLabel(names = [\"0\", \"1\"]))\n",
    "\n",
    "training_args = TrainingArguments(max_steps=max_training_steps, output_dir=model_folder)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3650476b-b9d7-4073-8041-a0a26be1ac88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "The following columns in the test set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate of predictions: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy\n",
    "pred_probs = trainer.predict(test_tokenized_dataset).predictions\n",
    "pred_classes = np.argmax(pred_probs, axis=1)\n",
    "print(f\"Error rate of predictions: {np.mean(pred_classes != test_tokenized_dataset['label'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a530ee43",
   "metadata": {},
   "source": [
    "\n",
    "## Taking a closer look at the training data\n",
    "\n",
    "Let's actually take a look at some of the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ab34483c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Based on all the negative comments about Taste...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I still have not received this.  Obviously I c...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;/tr&gt;The magazine is not worth the cost of sub...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This magazine is basically ads. Kindve worthle...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The only thing I've recieved, so far, is the b...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review label\n",
       "0  Based on all the negative comments about Taste...  good\n",
       "1  I still have not received this.  Obviously I c...   bad\n",
       "2  </tr>The magazine is not worth the cost of sub...  good\n",
       "3  This magazine is basically ads. Kindve worthle...   bad\n",
       "4  The only thing I've recieved, so far, is the b...   bad"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3c84e2",
   "metadata": {},
   "source": [
    "Zooming in on one particular data point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6ebf3a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'review': \"Based on all the negative comments about Taste of Home, I will not subscribeto the magazine. In the past it was a great read.\\nSorry it, too, has gone the 'way of the wind'.<br>o-p28pass4 </br>\", 'label': 'good'}\n"
     ]
    }
   ],
   "source": [
    "print(train.iloc[0].to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b839b33f",
   "metadata": {},
   "source": [
    "This data point is labeled \"good\", but it's clearly a negative review. Also, it looks like there's some funny HTML stuff at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e608bbc6",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "Take a look at some more examples in the dataset. Do you notice any patterns with bad data points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "82e43ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with unparsed html tags: 5361\n",
      "                                                 review label  has_html  \\\n",
      "0     Based on all the negative comments about Taste...  good      True   \n",
      "5     The magazines are great, but I never received ...  good      True   \n",
      "10    </div>It's not the fault of the magazine, I ju...  good      True   \n",
      "11    <li>dispatchEventBest magazine for current and...   bad      True   \n",
      "12    <li>onEmptiedBoth my husband and I really enjo...   bad      True   \n",
      "...                                                 ...   ...       ...   \n",
      "6643  <!--   -->Such a great magazine for kids!<h4 c...   bad      True   \n",
      "6646    <ul>Will not download. Keep getting error.</TR>  good      True   \n",
      "6647  Fantastic.....makes me yean for the English ci...   bad      True   \n",
      "6652  </div>Love this magazine as do grandkids ages ...   bad      True   \n",
      "6654   Left a lot to be desired.<div class=\"api-level\">  good      True   \n",
      "\n",
      "      valid_label  \n",
      "0            True  \n",
      "5            True  \n",
      "10           True  \n",
      "11           True  \n",
      "12           True  \n",
      "...           ...  \n",
      "6643         True  \n",
      "6646         True  \n",
      "6647         True  \n",
      "6652         True  \n",
      "6654         True  \n",
      "\n",
      "[1305 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "df = train\n",
    "\n",
    "# Create a new column to store whether each data point has html tags in the reviews column\n",
    "df['has_html'] = df['review'].apply(lambda x: BeautifulSoup(x, 'html.parser').find() is not None)\n",
    "df_filtered_html = df[df['has_html'] == False]\n",
    "\n",
    "print(f\"Number of rows with unparsed html tags: {len(df_filtered_html)}\")\n",
    "print(df[df['has_html'] == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2cc3f874-73e1-4195-be5b-32657ebbcc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label column contains only 'good' and 'bad' values.\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any labels other than 'good' or 'bad'\n",
    "unique_labels = df['label'].unique()\n",
    "if set(unique_labels) != {'good', 'bad'}:\n",
    "    print(f\"The label column contains values other than 'good' or 'bad': {unique_labels}\")\n",
    "else:\n",
    "    print(\"The label column contains only 'good' and 'bad' values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae38448f",
   "metadata": {},
   "source": [
    "## Issues in the data\n",
    "\n",
    "It looks like there's some funny HTML tags in our dataset, and those datapoints have nonsense labels. Maybe this dataset was collected by scraping the internet, and the HTML wasn't quite parsed correctly in all cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664845e4",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "To address this, a simple approach we might try is to throw out the bad data points, and train our model on only the \"clean\" data.\n",
    "\n",
    "Come up with a simple heuristic to identify data points containing HTML, and filter out the bad data points to create a cleaned training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5990cdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_bad_data(review: str) -> bool:\n",
    "    # YOUR CODE HERE\n",
    "    return '<' in review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092849c1",
   "metadata": {},
   "source": [
    "## Creating the cleaned training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e9c7671e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3998\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>has_html</th>\n",
       "      <th>valid_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I still have not received this.  Obviously I c...</td>\n",
       "      <td>bad</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This magazine is basically ads. Kindve worthle...</td>\n",
       "      <td>bad</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The only thing I've recieved, so far, is the b...</td>\n",
       "      <td>bad</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This is one magazine I really love. It has pri...</td>\n",
       "      <td>good</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Did not. Open.</td>\n",
       "      <td>bad</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review label  has_html  \\\n",
       "1  I still have not received this.  Obviously I c...   bad     False   \n",
       "3  This magazine is basically ads. Kindve worthle...   bad     False   \n",
       "4  The only thing I've recieved, so far, is the b...   bad     False   \n",
       "6  This is one magazine I really love. It has pri...  good     False   \n",
       "7                                     Did not. Open.   bad     False   \n",
       "\n",
       "   valid_label  \n",
       "1         True  \n",
       "3         True  \n",
       "4         True  \n",
       "6         True  \n",
       "7         True  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean = train[~train['review'].map(is_bad_data)]\n",
    "print(len(train_clean))\n",
    "train_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1740bf3b",
   "metadata": {},
   "source": [
    "## Evaluating a model trained on the clean training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0e83abad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e5e3c7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf_clean = clone(sgd_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6f72b0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sgd_clf_clean.fit(train_clean['review'], train_clean['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775ebff4",
   "metadata": {},
   "source": [
    "This model should do significantly better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "80b78100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.9%\n"
     ]
    }
   ],
   "source": [
    "evaluate(sgd_clf_clean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
